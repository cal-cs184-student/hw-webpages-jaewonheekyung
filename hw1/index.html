<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
				text-align: justify;
				line-height: 1.6;

			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Name: Jaewon Hur, Heekyung Lee </div>

		<br>

		Link to webpage: <a href="https://github.com/cal-cs184-student/hw-webpages-jaewonheekyung">https://github.com/cal-cs184-student/hw-webpages-jaewonheekyung</a>
		
		<br>

		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw1-kyunnilee">https://github.com/cal-cs184-student/sp25-hw1-kyunnilee</a>
		<br>
		<!--
		We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		<p><b>This is a write-up for Homework 1 of CS184/284A Spring 2025.</b>
		<p>
			In this homework,
			(1) we implemented a <I>simple rasterizer</I> that can draw triangles to draw pictures.(2) We also implemented <I>supersampling</I> to prevent <I>jaggies</I> and improve the quality of the rendered image. Then, we implemented (3) <I>transformations</I>  and (4) <I>barycentric coordinates</I> to draw a triangle with a texture. Finally, we implemented (5),(6) <I>mipmapping</I> to improve the quality of the <I>texture mapping</I>.
		</p><br>

		<h2>Task 1: Drawing Single-Color Triangles</h2>
		In task 1, we implement a simple rasterizer that can draw triangles. We implemented the rasterization algorithm that fills the triangle with a single color.<br><br> Below, we explain how we implemented the rasterizer algorithm and provided an example of a rasterized triangle image.

		<h3>[1] Rasterization Algorithm We Used:</h3>
		<p>
			We use a bounding box algorithm to rasterize the triangle. We compute the bounding box by determining the smallest axis-aligned rectangle that contains the triangle. The bounding box is computed by the minimum and maximum x and y coordinates of the triangle vertices.
		</p>
		<p>
			After computing the bounding box, we iterate over all the pixels in the bounding box. For each pixel, we check if the pixel is inside the triangle using function <code>is_inside_triangle()</code>. <br> <br> If the pixel is inside the triangle, we color the pixel with the color of the triangle.(<code>fill_pixel()</code>) Here, each pixel is sampled only once at its center <code>(x + 0.5, y + 0.5)</code>.

			When we define the is_inside_triangle, we have to check for both side of the normal vectors.<br><br>
			For each line vector l-*, we consider two conditions <code>(l_0 >=0 && l_1 >=0 && l_2 >=0) or (l_0 <=0 && l_1 <=0 && l_2 <=0)</code> since the normal vector can be either side of the triangle.
		</p>
		<p>
			The rasterizer algorithm is in the function <code>rasterize_triangle</code> in <code>rasterizer.cpp</code>.
		</p>

		<h3>Example image of a rasterized triangle:</h3>
		<figure>
			<img src="../hw1/image/screenshot_2-23_20-49-0.png" alt="" style="width:100%"/>
			<figcaption> svg/test4.svg </figcaption>
		</figure>

		<h3>[2] Efficiency Explanation</h3>
		<p>
			Our rasterization algorithm is efficient because it only iterates over the <I>pixels in the bounding box of the triangle</I>. This is much faster than iterating over <I>all</I> the pixels in the image. Additionally, we use the bounding box to quickly determine if a pixel is inside the triangle. This reduces the number of computations needed to rasterize the triangle.
		</p><br>

		<h2>Task 2: Antialiasing by Supersampling</h2>
		Supersampling is a technique used to reduced aliasing and to imporve the quality of rasterized images by sampling multiple points <b> within a pixel </b> and averaging the values to reduce jaggies. <br><br> In this task, we implemented supersampling to improve the quality of the rendered image. Below, we explain how we implemented supersampling and provide examples of images rendered with different supersample rates.

		<h3>[1] Supersampling Algorithm We Used:</h3>
		<p>
			To implement supersampling, we define a sample buffer, where the number of subpixels within each pixel is determined by the <code>sample_rate</code> parameter. Each pixel (px, py) is divided into <code> sqrt(sample_rate) x sqrt(sample_rate) </code> subsamples.<br><br> We loop through exah subsample and do a point-in-triangle test (<code>is_inside_triangle()</code>). To accurately position the sample points in the <I> sample buffer</I>, we calculate the coordinates using <code>sample_x = px + (i + 0.5f) / sqrt_sample_rate;</code> to ensure the points are correctly centered when locating the pixel. If the subsample is inside the triangle, we store the color in the <color> sample_buffer </color>. <br><br> On the last part using <code>resolve_to_framebuffer </code>, we simply average the color of the subpixels to get the final color of the pixel.
		</p>
		<h3>[2] Why is Supersampling Useful?</h3>
		<p>
			Supersampling is useful because it reduces aliases such as jaggies. We reduce high frequency artifacts by sampling multiple points within the pixel. This results in a smoother image. Especially, sharp and small tirangles fall between pixel boundaries which can be fixed using Supersampling method. Below in the images, we show some examples with different supersample rates.
		</p><br>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw1/image/screenshot_2-23_20-55-55.png" width="400px"/>
				  <figcaption>Supersample rate: 1</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw1/image/screenshot_2-23_20-55-58.png" width="400px"/>
				  <figcaption>Supersample rate: 4</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw1/image/screenshot_2-23_20-56-1.png" width="400px"/>
				  <figcaption>Supersample rate: 9</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw1/image/screenshot_2-23_20-56-3.png" width="400px"/>
				  <figcaption>Supersample rate: 16</figcaption>
				</td>
			  </tr>
			</table>
		</div><br> 

		<h3>[3] Modification in Rasterization Pipeline</h3>
		<p>
			This is the original Rasterization Pipeline:<br>
			<li><strong>Vertex Processing</strong> → Transform vertices to screen space</li>
			<li><strong>Primitive Assembly</strong> → Convert vertices into triangles</li>
			<li><strong>Rasterization</strong> → Convert triangles into pixels</li>
			<li><strong>Fragment Processing</strong> → Apply colors, textures, and lighting</li>
			<li><strong>Output to Framebuffer</strong> → Store final image for rendering</li>
		</p>
		<p>
			To implement Supersampling, these modifications were made to the rasterization pipeline:<br>
			<b>(1) Increase sampling per pixel.</b> <br>
			<b>(2) Enlarge the Sample Storage:</b> We use <code> sample_buffer </code> to hold more than one color per pixel.<br>
			<b>(3) Add <code> resolve_to_framebuffer() </code>:</b> We do a final pass to average the colors and write them to the framebuffer.
		</p>

		<h2>Task 3: Transforms</h2>
		<h3>[1] Translation</h3>
		<b> Moves an object in 2D space without changing its shape, size or orientation. </b>
		<p>
			We use a translation matrix (3x3) used in homogeneous coordinates to move the object. The translation matrix is defined as below: <br>
			\[ \begin{bmatrix} 1 & 0 & t_x \\ 0 & 1 & t_y \\ 0 & 0 & 1 \end{bmatrix} \]
			<br> <br>When multiplying a point (x, y, 1) by this matrix, it moves by (dx, dy), resulting in (x + dx, y + dy, 1).
		</p><br>
		<h3>[2] Scale</h3>
		<b> Scales an object in 2D space without changing its shape, size or orientation. </b>
		<p>
			We use a scale matrix (3x3) used in homogeneous coordinates to scale the object. The scale matrix is defined as below: <br>
			\[ \begin{bmatrix} s_x & 0 & 0 \\ 0 & s_y & 0 \\ 0 & 0 & 1 \end{bmatrix} \]
			<br> <br>When multiplying a point (x, y, 1) by this matrix, it scales by (sx, sy), resulting in (sx * x, sy * y, 1).
		</p><br>
		<h3>[3] Rotation</h3>
		<b> Rotates an object in 2D space without changing its shape, size or orientation. </b>
		<p>
			We use a rotation matrix (3x3) used in homogeneous coordinates to rotate the object. The rotation matrix is defined as below: <br>
			\[ \begin{bmatrix} cos(\theta) & -sin(\theta) & 0 \\ sin(\theta) & cos(\theta) & 0 \\ 0 & 0 & 1 \end{bmatrix} \]
			<br> <br>When multiplying a point (x, y, 1) by this matrix, it rotates by \(\theta\) degrees, resulting in (x', y', 1).
		</p><br>
		<h3>[4] Hierarchical Transformation</h3>
		<p>
			In this example, it is essential to consider the concept of <b>hierarchical transformation</b> since when the parts of the body of the robot does not work independently. We use a <I>parent-child relationship</I> when we apply the change.<br>
			The child transformation depends on the parent's transformation, which the order of transformation always follows a matrix stack approach, which applies transformation in a hierarchical order.
		</p>
		<h3>Example of transformation</h3>
		<p> Below, we draw a red robot and give some rotational changes on its left arm. </p><br>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw1/image/screenshot_2-23_21-24-19.png" width="400px"/>
				  <figcaption>transforms/robot.svg</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw1/image/screenshot_2-23_21-24-8.png" width="400px"/>
				  <figcaption>transforms/my_robot.svg</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p> Here in our robot, we changed the second segment of the arm to point downwards to make it hold its hand as shown in the picture.</p>

		<h2>Task 4: Barycentric coordinates</h2>
		<h3>[1] Barycentric Coordinates</h3>
		<p>
			Barycentric coordinates are a way to describe the position of a point relative to the corners of a triangle.
			Instead of using standard (x, y) coordinates, they express the point as a mix of the triangle’s three vertices, like a weighted average.
			The weight coefficients tell us how much influence each vertex has, if they all add up to 1 and are non-negative, the point is inside the triangle; otherwise, it is outside of the triangle.
		</p>
		<h3>[2] Implementation: rasterize_interpolated_color_triangle</h3>
		<p>
			In our rasterize_interpolated_color_triangle function, we use these barycentric weights to rasterize the triangles’ colors based off of the three colors of each vertex of the triangle.
			We compute the weights, so called alpha, beta, and gamma, by taking the ratio of the area of a triangle between the sample point and two vertices to the total area of the triangle.
			By doing so, we are able to compute the color based on the weights by taking color0 * alpha + color1 * beta + color2 * gamma.
		</p>
		<ul>
			<li>Barycentric Weights alpha: \( alpha = area(sample_x, sample_y, x1, y1, x2, y2) / total_area \)</li>
			<li>Barycentric Weights beta: \( beta = area(x0, y1, sample_x, sample_y, x2, y2) / total_area \)</li>
			<li>Barycentric Weights gamma: \( gamma = 1.0 - alpha - beta \)</li>
		</ul>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw1/image/task4.png" width="400px"/>
				  <figcaption>basic/test7.svg</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p>
			In the image above, the triangles in the circle are all rasterized based on the barycentric interpolation colors.
			The reason the colors vary as a gradation is because every triangle is rasterized with the colors computed with the barycentric interpolation of the three vertices.
		</p>

		<h2>Task 5: "Pixel sampling" for texture mapping</h2>
		<h3>[1] Pixel Sampling and Texture Mapping</h3>
		<p>
			Texture mapping involves wrapping a 2D image onto a 3D surface by mapping texture coordinates (UV coordinates) to object coordinates.
			Since textures do not always align perfectly with the screen’s pixel grid, pixel sampling determines how the texture is read and displayed at each pixel.
			In the rasterize_textured_triangle function, we set every sample point’s barycentric differentials of the uv coordinates and pass them into the sample parameters.
			Then, we invoke the sample function that samples the pixels depending on the sampling methods.
			Here, we have two sampling functions: sample_nearest and sample_bilinear.
		</p>
		<h3>[2] Nearest Neighbors</h3>
		<p>
			Nearest Neighbors sampling selects the nearest texture pixel (texel) of the uv coordinate of the sample point.
			In the sample_nearest function, it returns the color of the texel that is closest to the uv coordinate.
		</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw1/image/task5-nearest1.png" width="400px"/>
				  <figcaption>Nearest Sampling with 1 Sample</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw1/image/task5-nearest16.png" width="400px"/>
				  <figcaption>Nearest Sampling with 16 Samples</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<h3>[3] Bilinear Interpolation</h3>
		<p>
			Bilinear Interpolation takes the four adjacent texels of the uv coordinate and operates linear interpolation within the two pairs of the texel colors.
			Then, it takes another linear interpolation between the resultant colors of the two texel pairs.
			That color is the final bilinear interpolated color of the sample point.
			In the sample_bilinear function, we retrieve four adjacent texels with respect to the uv coordinate computed based on the sample point, and then take a total 3 lerps between the texels.
		</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw1/image/task5-bilinear1.png" width="400px"/>
				  <figcaption>Bilinear Sampling with 1 Sample</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw1/image/task5-bilinear16.png" width="400px"/>
				  <figcaption>Bilinear Sampling with 16 Samples</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
		<h3>[1] Level Sampling</h3>
		<p>
			Level sampling is a method in texture mapping that helps control how textures look when objects are viewed from different distances.
			When a 3D object is far away, its texture can appear overly detailed for the number of pixels available on the screen, leading to visual issues like jagged edges or flickering.
			To prevent this, level sampling selects from a set of pre-scaled texture versions, known as mipmaps, which are lower-resolution copies of the original texture designed to match the viewing distance more effectively.
		</p>
		<h3>[2] Implementation: sample</h3>
		<p>
			In the sample function, we first determine the level computed by the get_level function passed by an argument of SampleParams.
			Here, we use the following equation:
			\[ level = log2(max(abs(sp.p_dx_uv - sp.p_uv), abs(sp.p_dy_uv - sp.p_uv))) \]
			The sampling method is determined by the P command between P_NEAREST and P_LINEAR.
			For the level sampling, the L command determines which level sampling method to incorporate with: zero level, nearest level, and bilinear level samplings.
		</p>
		<h3>[3] Zero Level Sampling</h3>
		<p>
			Zero level sampling merely passes in a level of 0 to the sampling method.
		</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw1/image/task6-zero-nearest.png" width="400px" title="Zero Level Nearest Sampling"/>
				  <figcaption>Zero Level Nearest Sampling</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw1/image/task6-zero-bilinear.png" width="400px" title="Zero Level Bilinear Sampling"/>
				  <figcaption>Zero Level Bilinear Sampling</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<h3>[4] Nearest Level Sampling</h3>
		<p>
			Nearest level sampling passes in a level that is rounded to the nearest integer.
			The logarithmic float value will be rounded up or down based on the precision.
			We use the nearest level as its level sampling.
		</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw1/image/task6-nearest-nearest.png" width="400px" title="Nearest Level Nearest Sampling"/>
				  <figcaption>Nearest Level Nearest Sampling</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw1/image/task6-nearest-bilinear.png" width="400px" title="Nearest Level Bilinear Sampling"/>
				  <figcaption>Nearest Level Bilinear Sampling</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<h3>[5] Bilinear Level Sampling</h3>
		<p>
			Bilinear level sampling computes both samples with level of floor(level) and ceil(level).
			Then, we operate linear interpolations between the colors acquired from sampling the texels.
			Lastly, we do another linear interpolation (lerp) on the colors generated by the two sampling methods with two different levels.
			For bilinear level and bilinear sampling, also known as Trilinear Sampling, we do bilinear interpolation twice, which means there are 8 texels read. Also, there are total 7 linear interpolations computed.
		</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw1/image/task6-bilinear-nearest.png" width="400px" title="Bilinear Level Nearest Sampling"/>
				  <figcaption>Bilinear Level Nearest Sampling</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw1/image/task6-bilinear-bilinear.png" width="400px" title="Bilinear Level Bilinear Sampling"/>
				  <figcaption>Bilinear Level Bilinear Sampling</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<h3>[6] Tradeoffs: Speed, Memory Usage, Antialiasing Power</h3>
		<p>
			<b>Speed</b><br>
			Zero level sampling is the fastest since it always grabs the highest-resolution texture, but this can slow things down when rendering distant objects.
			Nearest level sampling is a bit slower because it picks the closest mipmap level, reducing unnecessary detail.
			Bilinear level sampling is the slowest since it blends between two mipmap levels, making textures look smoother but requiring more processing.
			<br><b>Memory Usage</b><br>
			Zero level sampling uses the least memory since it only stores the original texture.
			Nearest level sampling needs more storage for mipmaps, but they help optimize performance.
			Bilinear level sampling takes up the most memory because it accesses multiple mipmaps at once to smooth transitions.
			<br><b>Antialiasing Power</b><br>
			Zero level sampling has the worst antialiasing, leading to jagged textures and shimmering.
			Nearest level sampling helps by using mipmaps, though it can cause sudden texture shifts.
			Bilinear level sampling is the best at reducing aliasing, blending mipmap levels for a smoother, more natural look.
		</p>

		<h2>(Optional) Task 7: Extra Credit - Draw Something Creative!</h2>
		

		</div>
	</body>
</html>